<p class="lead" style="font-size:1.12rem; font-weight:500; color:#111827; margin-bottom:1rem;">
I'm B. Manubolu — a QA technologist focused on automation, test infrastructure, and applying AI to make testing faster, more reliable, and reproducible.
</p>

<div class="readable-page" style="max-width:760px; margin:0 auto; padding:0 1rem; line-height:1.75; font-size:18px; color:#0f172a; box-sizing:border-box;">

  <h3 id="summary">Summary</h3>
  <ul>
    <li>14+ years in software quality engineering with a strong emphasis on test automation, CI/CD integration, and infrastructure for large-scale automated execution.</li>
    <li>My work centers on building reliable test frameworks, scalable execution infrastructure, reproducible playbooks, and automation-first pipelines that can be integrated into modern dev workflows.</li>
  </ul>

  <h3 id="technical-focus">Technical focus</h3>
  <ul>
    <li>Test automation frameworks: design and implementation using Selenium, WebdriverIO, Cypress, Playwright, TestCafe, and Rational Functional Tester.</li>
    <li>Visual testing &amp; validation: Applitools and image-comparison strategies for UI regression detection.</li>
    <li>Languages &amp; frameworks: Java and TypeScript for framework development; BDD (Cucumber, Jasmine), TestNG, and other test runners.</li>
    <li>API and integration testing: Postman collections, contract validation, and automated API checks integrated into pipelines.</li>
    <li>CI/CD &amp; DevOps: Jenkins, Bamboo, GitHub Actions, AWS CodeBuild / CodePipeline — building pipelines that run tests as quality gates and generate actionable reports.</li>
    <li>Test execution infrastructure: containerized runners using AWS ECS, secrets management, and event-driven orchestration to reduce execution time and increase parallelism.</li>
    <li>Data &amp; tooling: synthetic test-data generation patterns, schema-constrained record generation, and privacy-aware data synthesis.</li>
    <li>Flakiness detection &amp; triage: automated rerun strategies, flakiness metrics, log aggregation, and triage playbooks to quickly identify and remediate flaky tests.</li>
    <li>Observability &amp; metrics: test cycle time, flakiness rate, escape rate, and pass/fail trends used to prioritize automation effort and reduce feedback time.</li>
    <li>AI-assisted QA: prompt templates and small tooling to speed test-case generation, log triage, and test-data synthesis while maintaining reproducibility and auditability.</li>
  </ul>

  <h3 id="selected-technical-achievements">Selected technical achievements</h3>
  <ul>
    <li>Reduced manual testing effort by ~25% through modular automation frameworks and reusable test components.</li>
    <li>Cut test execution time by 50–65% by containerizing runners and optimizing parallel execution on AWS ECS.</li>
    <li>Implemented end-to-end CI/CD pipelines that automatically build, test, and gate releases using GitHub Actions, Jenkins, and AWS CodePipeline.</li>
    <li>Built reproducible playbooks (prompts + scripts) for AI-assisted test-case generation and triage so teams can rapidly reproduce experiments and evaluate model outputs.</li>
    <li>Established actionable flakiness detection with automated reruns and prioritized fixes using telemetry and historical failure analysis.</li>
  </ul>

  <h3 id="how-i-work-technical-practices">How I work (technical practices)</h3>
  <ul>
    <li>Automation-first and pragmatic: focus on high-value automation and modular framework design to minimize brittle tests.</li>
    <li>Infrastructure-as-code for test runners: containerized, versioned execution environments to ensure reproducible results across CI and local runs.</li>
    <li>Data-conscious testing: generate constrained synthetic data and sanitize any real data used in experiments to meet privacy requirements.</li>
    <li>Metric-driven improvements: instrument tests and pipelines to gather meaningful metrics and use them to drive automation priorities.</li>
    <li>Reproducible artifacts: every playbook includes prompts, code snippets, and exact commands so others can copy and execute experiments reliably.</li>
  </ul>

</div>

<p>Get in touch</p>
<ul>
  <li>GitHub: <a href="https://github.com/bmanubolu">bmanubolu</a></li>
  <li>Email: you@example.com (replace with your preferred contact)</li>
</ul>

<p>Contribute</p>
<ul>
  <li>I welcome contributions: add playbooks, prompt templates, or small tools under <code class="language-plaintext highlighter-rouge">use-cases/</code>, <code class="language-plaintext highlighter-rouge">prompts/</code>, or <code class="language-plaintext highlighter-rouge">tools/</code>. Include a short “how to run” and expected outputs so others can reproduce your results quickly.</li>
</ul>
